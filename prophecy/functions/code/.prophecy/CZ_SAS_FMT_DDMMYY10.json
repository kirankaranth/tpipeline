{"initCode": "", "code": "\"\"\" UDF cz_sas_fmt_ddmmyy10 \"\"\"\n\nfrom pyspark.sql.functions import udf\nfrom pyspark.sql.types import DateType\n\n\n@udf(returnType=DateType())\ndef cz_sas_fmt_ddmmyy10(param):\n    # pylint: disable=import-outside-toplevel\n    from re import match, findall\n    from datetime import date\n\n    if param is None:\n        return None\n\n    proc = False\n    result = None\n\n    pattern = r\"^(\\d{1,2})[-/](\\d{1,2})[-/](\\d{4})\\D*\"\n    if match(pattern, param):\n        proc = True\n        day, month, year = findall(pattern, param)[0]\n\n    pattern = r\"^(\\d{4})[-/](\\d{1,2})[-/](\\d{1,2})\\D*\"\n    if match(pattern, param):\n        proc = True\n        year, month, day = findall(pattern, param)[0]\n\n    if proc:\n        year = int(year)\n        month = int(month)\n        day = int(day)\n        # if month>12: day,month = month,day\n\n        try:\n            result = date(year=year, month=month, day=day)\n        except Exception as e:\n            print(f\"An exception occurred: {str(e)}\")\n            result = None\n\n    return result\n"}